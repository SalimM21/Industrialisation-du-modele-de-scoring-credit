# Credit Scoring ML Platform

## üìå Pr√©sentation du projet

Cette plateforme permet de :

- Entra√Æner et comparer plusieurs mod√®les de scoring cr√©dit (Logistic Regression, XGBoost, Neural Network).
- Suivre et d√©tecter les d√©rives des donn√©es et du mod√®le.
- D√©ployer un mod√®le en production via une API FastAPI.
- Industrialiser le mod√®le avec Docker, CI/CD et MLflow pour le suivi des exp√©rimentations.
- G√©n√©rer des dashboards de monitoring et de performance via Evidently.

---

## üìû Structure du projet

```
credit_scoring/
‚îú‚îÄ data/                  # Donn√©es brutes et transform√©es
‚îú‚îÄ notebooks/             # Notebooks d'exploration, comparaison mod√®les et monitoring
‚îú‚îÄ src/                   # Code source : preprocessing, training, export, API, monitoring
‚îú‚îÄ models/                # Mod√®les sauvegard√©s (Pickle / ONNX / PMML)
‚îú‚îÄ dashboards/            # Dashboards HTML Evidently
‚îú‚îÄ tests/                 # Tests unitaires
‚îú‚îÄ Dockerfile
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ entrypoint.sh
‚îú‚îÄ requirements.txt
‚îú‚îÄ Makefile
‚îú‚îÄ config.yaml
‚îú‚îÄ logger.py
‚îú‚îÄ github_actions.yml
‚îî‚îÄ Jenkinsfile
```

---

## ‚ö°Ô∏è Commandes principales

### 1Ô∏è‚É£ Installation des d√©pendances
```bash
make install
```

### 2Ô∏è‚É£ Build Docker
```bash
make build
```

### 3Ô∏è‚É£ Lancer les tests unitaires
```bash
make test
```

### 4Ô∏è‚É£ Export du mod√®le
```bash
make export_model
```

### 5Ô∏è‚É£ Enregistrer le mod√®le dans MLflow
```bash
make register_mlflow
```

### 6Ô∏è‚É£ Lancer l‚ÄôAPI FastAPI
```bash
make run_api
```
- API accessible sur : `http://localhost:8000`  
- Docs interactives Swagger : `http://localhost:8000/docs`

### 7Ô∏è‚É£ G√©n√©rer le dashboard Evidently
```bash
make monitor
```
- Dashboard HTML g√©n√©r√© : `dashboards/credit_model_monitoring.html`

### 8Ô∏è‚É£ D√©ployer l‚ÄôAPI Docker localement
```bash
make deploy
```

### 9Ô∏è‚É£ Nettoyer le projet
```bash
make clean
```

---

## üñº Diagramme du flux global (Mermaid)

```mermaid
graph LR
    A[DATA: brutes] --> B[DATA: transform√©es]
    B --> C[DATA: r√©f√©rentielles]
    C --> D[DATA: nouvelles pour recalibrage]
    
    B --> E[NOTEBOOKS: exploration]
    B --> F[NOTEBOOKS: comparaison mod√®les]
    D --> G[NOTEBOOKS: monitoring d√©rive]
    
    B --> H[SRC: preprocessing.py]
    B --> I[SRC: feature_selection.py]
    B --> J[SRC: split_data.py]
    H --> K[SRC: train_lr.py]
    H --> L[SRC: train_xgb.py]
    H --> M[SRC: train_nn.py]
    K --> N[SRC: evaluate_models.py]
    L --> N
    M --> N
    N --> O[SRC: export_model.py]
    O --> P[SRC: register_mlflow.py]
    
    P --> Q[SRC: main.py / API FastAPI]
    Q --> R[DASH: dashboards / monitoring]
    
    SRC --> S[CICD: GitHub Actions / Docker Compose / Jenkins]
```

---

## üß∞ CI/CD

- **GitHub Actions** : build, tests et d√©ploiement automatis√©s.
- **Jenkinsfile (optionnel)** : pipeline √©quivalente Jenkins.
- **Docker Compose** : orchestration multi-services (API + MLflow + Monitoring).

---

## üìù Notes

- Mod√®les export√©s en **Pickle, ONNX et PMML** pour compatibilit√© production.  
- D√©tection de d√©rive automatis√©e via **Evidently** et `retrain_trigger.py`.  
- Logs centralis√©s via `logger.py`.  
- Param√®tres globaux (chemins, hyperparam√®tres, seuils) dans `config.yaml`.  

---

## üìö R√©f√©rences

- [FastAPI Documentation](https://fastapi.tiangolo.com/)  
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)  
- [Evidently Documentation](https://docs.evidentlyai.com/)  
- [XGBoost Documentation](https://xgboost.readthedocs.io/)  
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

